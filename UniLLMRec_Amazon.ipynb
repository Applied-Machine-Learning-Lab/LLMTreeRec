{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:51:10.505892900Z",
     "start_time": "2023-12-12T15:51:05.889206300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "f = open('./data/meta_Movies_and_TV.json', 'r', encoding='utf-8')\n",
    "data = []\n",
    "i = 0\n",
    "for l in f.readlines():\n",
    "  dic = json.loads(l)\n",
    "  data.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def correct_spaces_and_symbols(input_string):\n",
    "    cleaned_string = ' '.join(input_string.split())\n",
    "    cleaned_string = cleaned_string.replace('. ', '.')\n",
    "    cleaned_string = cleaned_string.replace(':', ': ')\n",
    "    \n",
    "    cleaned_string = ' '.join(cleaned_string.split())\n",
    "\n",
    "    return cleaned_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:51:10.521521400Z",
     "start_time": "2023-12-12T15:51:10.505892900Z"
    }
   },
   "id": "a8ba20a0c29b42e6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ID_title_dict = {\"NULL\": 0}\n",
    "title_ID_dict = {\"NULL\": 0}\n",
    "dataset = {}\n",
    "for sample in data:\n",
    "    sample[\"title\"] = sample[\"title\"].strip()\n",
    "    sample[\"title\"] = sample[\"title\"].replace(\"&amp;\", \"&\")\n",
    "    sample[\"title\"] = correct_spaces_and_symbols(sample[\"title\"])\n",
    "    ID_title_dict[sample[\"asin\"]] = sample[\"title\"]\n",
    "    title_ID_dict[sample[\"title\"]] = sample[\"asin\"]\n",
    "        \n",
    "    if sample[\"asin\"] == \"\" or sample[\"title\"] == \"\":\n",
    "        continue\n",
    "    if len(sample['category']) <= 1:\n",
    "        continue\n",
    "\n",
    "    sample[\"also_view\"].extend(sample[\"also_buy\"])\n",
    "    history_list = sample[\"also_view\"][-50:]\n",
    "    if len(history_list) < 5:\n",
    "        continue\n",
    "    dataset[sample[\"asin\"]] = {\"history\": history_list, \"category\": sample['category']}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:51:11.255948600Z",
     "start_time": "2023-12-12T15:51:10.521521400Z"
    }
   },
   "id": "796973d53b8bb18e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for id in dataset.keys():\n",
    "    clicks = []\n",
    "    for click_id in dataset[id][\"history\"]:\n",
    "        if click_id in dataset:\n",
    "            clicks.append(click_id)\n",
    "    dataset[id][\"history\"] = clicks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:52:23.657719400Z",
     "start_time": "2023-12-12T15:52:23.333540Z"
    }
   },
   "id": "5486e0a841e003fc"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B0142YXYPW', 'B003RACH88', 'B0069B0F72', 'B001CIOCMQ', 'B001QDAFIM', 'B008H6GHG0', 'B00L9S1VZK', 'B00008YLUN', 'B000VUQ4FE', '1562196308', 'B000WM84UO', '6302409829', 'B00XV97FEQ', 'B00WLL7X6K', 'B011MUA5J2', 'B007LNBSLE', 'B005DL6PSC', 'B01995ZFYM', 'B00PTUB45Q', '7885727513', '1611800277', 'B000FJTV9C', 'B00BKQ12F0', 'B00HL2HGEI', 'B00SEAAZ7G', 'B002AMVE9W', 'B009FFHWRU', 'B000640XOS', 'B00UL90D4I', 'B001MEJY96', '6305293651', 'B004HV1NMM', 'B002Q1KN6M', 'B00004WMMY', 'B0006J28E6', 'B000HT3862', 'B000HD1MUM', 'B00005UF7N', 'B00C9VZ73S', '5553799260', 'B001502LNI', 'B00J2FIQBY', 'B0056031N2', 'B001N6FPQY', 'B00VX21VWK', 'B0015RB6MI', 'B000OONQAI', 'B00440OFZS', 'B004FKKU92', 'B001L4L8UA', 'B0009Y276C', 'B00IZE00MQ', 'B004LGGXI2', 'B00PLYU8JS', 'B00005BCP6', 'B000PUAIMU', 'B001AVQJH6', 'B000DN5VN0', 'B004K9WWAI', 'B00000ICEY', 'B00JPSYPCM', '6301016416', 'B00QJAZ514', 'B0000AGQ68', 'B001D7T45Q', 'B000067IZL', 'B00IIQY08Q', 'B000RXZL0E', 'B00I2YEHAA', 'B00BKX7PJ0', 'B001FPKJNM', 'B00CERJINC', 'B00GNIFHZG', 'B001PU8MYA', 'B019WMTVLA', 'B001COCOB6', 'B00007KK1X', 'B00X5UIYPK', 'B000WMA72M', 'B005C205RE', 'B00MEXP5YM', 'B00PFRFXB4', 'B004ZJHSXE', 'B002WAEOS0', 'B000S6LS6Q', 'B001O0TWY0', 'B00LU4R52G', 'B007AFBYEE', 'B00005KCB5', 'B001HN68ZU', 'B007C3W2ZY', 'B00E1LRCY6', 'B00B74MJOS', 'B00005JXXZ', 'B00JVVFM3O', 'B00008OM40', 'B001L9UG6W', 'B008BMMXF4', 'B00DUD7VDI', 'B00BR06CB8', 'B00006G8I8', 'B00B999EBW', 'B009YQJ31S', 'B01CGLZLQI', 'B00BSGTVPU', 'B00PGTN980', 'B0016MJ6G0', 'B00GLASWIA', 'B0030Y129G', 'B003BQYD6W', 'B00008HCAB', 'B005DKS1W6', 'B00803PGGM', 'B002V5HB6S', 'B000MUJX1A', 'B006VHJL5Q', 'B00PHK6J5S', 'B00FRUWAD8', 'B00S4YGUBC', 'B00FE7LVZC', 'B00VUK4YN8', 'B002C6VMJS', 'B00000IC82', 'B018MO7B2K', '6305762694', 'B00PLYU51Y', 'B00965ZJT2', 'B00007J6DM', 'B00DL47424', 'B007IY10EQ', 'B000EWBNYQ', 'B00EIDTDKS', 'B000GB5M1U', 'B000K1W06G', 'B009266RZU', 'B00514HM7E', 'B00L30II5A', 'B014VVNTN8', 'B007P3G5TU', 'B000GFLEAO', 'B0009MDPTC', 'B001RXB4K4', 'B00LYY75M2', 'B0000CG8I8', 'B00000F4F3', 'B018GZLLV2', 'B00FDZ7VZE', 'B005STRK4W', 'B000GH3CEI', 'B0002YLCUQ', 'B00OMCCI8Y', 'B001JXPC0U', 'B00FOHHO80', 'B00DUGC202', 'B005CHTXYK', 'B00000INUB', 'B000A2UBOS', 'B00UGQ9WRA', 'B00HUZ993M', 'B00008RV0F', '0767821408', 'B00005U8EO', 'B000NQQ4HE', '6302768837', 'B00EEIJRH6', 'B00092A1JE', 'B00GIP1SF2', 'B008XAT0QY', 'B0036APHQS', 'B005PTYOTY', 'B001B1879S', 'B0064F78MI', 'B017KNPQVW', 'B000MV9O18', 'B000T9Q8NA', 'B00KGFGLNE', 'B00005ALS5', 'B00009N84F', 'B00FFLBXLY', 'B011INA2RS', 'B00005AAF0', 'B00K3PJIUK', 'B00L9CDUAK', 'B006HBU0ME', 'B00CHYSQQC', 'B019OI2HDQ', 'B0002HODUO', 'B000TJ6PLU', 'B00005JP3K', 'B00RZXWU6C', 'B000PHX5M8', 'B01EIW2RGK', 'B0000CBXYW', 'B00005KA71', 'B000TSMODE', 'B004047XV6', 'B01F9IFR8M', 'B00DNLZQFW', 'B00F1BFLKC', 'B000OTHVWM', 'B00CAYH2P0', 'B00062IVOY', 'B007ZDZ16S', 'B00005JH9X', 'B006BZ6YMQ', 'B001ANQY38', 'B0024HH2WG', 'B00GMM19NW', '6304982747', 'B00EGSG93E', 'B00008IAJR', 'B0007CEXRM', 'B00AAGDMEK', 'B00HLSW6YC', 'B005BQTURC', 'B00006FDAM', 'B000A1IMI6', 'B008YYBYKE', 'B00R3O3QVQ', '0790745364', 'B00000I1IP', 'B001LXIDU4', 'B0009A407A', 'B00H7BJ04W', 'B002RT7TK6', 'B00DZP1BTQ', 'B009C30OIY', 'B000HXDWGO', 'B0172CGDKO', 'B001HQ8RLK', 'B001PSUM9K', 'B016VJM2M2', 'B00TPN7DEO', 'B00BQI4AJ2', 'B005TQACLC', 'B00004Z1FX', 'B01AO6WJMG', '0970810490', 'B002ZFEQ76', 'B000GKUTP0', 'B000063V8N', 'B000R7I44A', 'B00B5A9FNM', 'B000GETUDS', 'B0001OGUS6', 'B0031L5CJO', 'B01ENSOKK0', 'B000HLDFAE', '6300251551', 'B00L9S1VY6', 'B00595IBNY', 'B000OY9VCA', 'B000GGSMO4', 'B00EYTDWMG', 'B000CEV3SM', '6303929338', 'B01G2FHUAO', 'B0015L7RIG', 'B000056P5M', 'B000MTFFP4', 'B013YXK1YE', 'B0014567WU', 'B0009GZCIK', 'B007I1Q4MM', 'B00QMWEIOO', 'B01ASMCF5M', 'B00MIA0KM8', 'B009INAHSU', 'B005ENCIZI', 'B00005JM39', 'B00JHH1Y1G', 'B0013V9XQM', 'B0002KPIGE', 'B00DT55OM2', 'B002SSLY2A', 'B0006N2E50', 'B007PW2Y00', 'B001KEHAEE', 'B00SXNKEM0', 'B00MAMZ17S', 'B000NHG7DY', 'B0013527IO', 'B0009PVZY6', 'B004CYVZ40', 'B00U1U2SG8', 'B005MYEPX2', 'B00000IBT4', 'B01AXUERS2', 'B000GB5M1K', 'B004VRK4CC', 'B00DIG95H2', 'B0035ECHTK', 'B01B8MEXF6', 'B000Y11BBC', 'B00DV1XYTO', '1572524561', 'B01GXTF5FQ', 'B000UWK7II', 'B003ES5JEC', 'B000F2C76S', 'B0007GP7MI', 'B004THWPEY', 'B00005UW9K', 'B00P80Y2IS', 'B00QU7SQ2G', 'B000EOTVBQ', 'B005ZSFYMQ', 'B0178FUDC4', 'B002BYSG2C', 'B00CPSBNZG', 'B0084IHVUC', 'B001675YRA', 'B01C4B7URI', '6304209320', 'B0027FG29Y', 'B000068UE9', 'B00005TPLX', 'B000BVNRO4', 'B000G6BM0U', 'B003DZAMDO', '6305837406', 'B00IZ03WRK', 'B004RV70X8', 'B0017MO0U6', 'B00FAXTNIC', 'B001LEI7B8', 'B0013XZ6U2', 'B001GZJTIW', 'B01CDT63YM', 'B001UV4XEM', 'B00OHLRAJW', 'B002DGLR5Q', 'B000FFJ876', 'B00MRDWGTQ', 'B00029NMRM', 'B006GA7FWO', 'B004A8PR8I', 'B0016S7TQ8', 'B005FXXTAK', 'B000QXDEGS', 'B001QWQJ38', 'B0019UGYD2', 'B00GKEJMQS', 'B00127QL12', 'B0000D9PNS', 'B01E6CE17U', 'B000F3PL2E', '6300214966', 'B0018CAM7A', 'B000F48DBY', 'B00A33J90G', 'B002GLGHVM', 'B002JI94VM', 'B000QGDJF6', 'B000UR9TQY', 'B00006AUHU', 'B002C3JVHG', 'B002DU0RB2', 'B000HC2LIU', 'B018HEW22Y', 'B001LX4BRS', 'B000B64TX2', 'B0007CILLG', 'B005T5OBME', 'B00GI1EEQQ', 'B0016AKSP0', 'B000059TPD', 'B00AATGDY8', 'B002A5FCTC', 'B000A0LAIQ', 'B000LPQE22', 'B0001HAGTW', 'B00EIEPHBG', 'B00I6RS8Q2', 'B0001KL5HQ', 'B00EKFI1HA', 'B000NOKAGW', 'B00019GH8E', 'B007ISJSNW', 'B0010YSD68', 'B01BN1C8J0', 'B0000VCZNE', 'B006YCJUCW', 'B00BWDAGXK', 'B001BNFR6C', 'B00U8BDQK2', 'B00XKENZP0', 'B000LUYKU0', 'B000A6SFT2', 'B00LBU7QN2', 'B000V3LG22', 'B00IO9EWQM', 'B001PCJG2A', 'B00364K78C', 'B00Q3IU46I', 'B001AOI4OO', 'B000HOJTXI', 'B009WY24IG', 'B00BMC23Y6', 'B00P7ZD578', 'B003KWWDK0', 'B003X2O79W', 'B00M3MCW5O', 'B00SJFL3YA', 'B0006FFRJS', 'B00MBI0CB6', 'B00MEEVVV2', 'B00F53GGTQ', 'B0018W2L0G', 'B00157WT60', 'B001TKK3IO', 'B000FVMSMM', 'B0018AQ2RG', 'B000WOSAUQ', 'B000BKVS1E', 'B01G9CFV9C', 'B000UANYNK', 'B00005NGAJ', 'B001GP5TPY', 'B00EE25ELA', 'B000PEB8HA', 'B000O76FIU', 'B00005RIWX', 'B00KHW4XDQ', 'B00H7GZJNI', 'B000OCZ80G', 'B00CC0EOVC', 'B010E45ROA', 'B003N2JKXU', 'B00BI6SRVY', 'B005EMZ64Y', 'B00H91LVW4', 'B00006FD8X', 'B01ALA0LFM', 'B00004T3BR', '6302642531', 'B013OUGLDW', 'B00003CXLD', 'B00062J0G2', 'B000FQISIK', 'B001LNOLPU', '630234509X', 'B002CMGO5O', 'B00DTPRYY8', '6303234674', 'B0000YED1S', 'B00XVJ3MW0', 'B0007QS31A', 'B000EMGF7G', 'B00005O5CD', 'B00SL9CTRO', 'B00NSOP73A', 'B00005JKZM', 'B001LGXIGA', 'B0000A5BW1', 'B017HMM4DE', 'B000BO0LPO', 'B0002LNW2K', 'B000S0PLUG', 'B000255LFC', 'B00O3GUZ3Y', 'B0000A02TP', 'B0001M6588', 'B00GL4XCZ4', '6301906543', 'B00AZEWDMY', 'B00DF2DH8C', 'B00003ETIU', 'B005BXY1OM', 'B00008AORL', 'B00JAD6FYI', 'B000UCD4LU', 'B00JKJWUS2', 'B001LMAK92', 'B000YJH1AO', 'B002EP8TTS', 'B0013ND3MK', 'B00CPZH8ZI', 'B00LXDQ8PO', 'B01AJV7CQO', 'B00D2L8PWY', 'B006WXHJLC', 'B01FXM8W6I', 'B000ZBEPZU', 'B0026P4DFA', 'B000PC6YSK', 'B00OTADKSQ', 'B00842E6OM', 'B013U6UCMQ', 'B00AIQARTU', 'B00V4TU542', 'B00009L4TU', 'B00NBIH038', 'B003KWWDHS', 'B00O9ZSHUM', 'B00570XETC', 'B000B837X8', 'B00E1SFRFA', '6303675387', 'B00HFC90TI']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sdsc\\AppData\\Local\\Temp\\ipykernel_19188\\3964593522.py:3: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  select_sampleID = random.sample(dataset.keys(), sample_num)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sample_num = 500\n",
    "select_sampleID = random.sample(dataset.keys(), sample_num)\n",
    "print(select_sampleID)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:52:27.184518900Z",
     "start_time": "2023-12-12T15:52:27.176352100Z"
    }
   },
   "id": "19ad1212649a3bd7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "ID_tree = {}\n",
    "\n",
    "def update_tree(id, cate_words, tree_dict):\n",
    "    for i in range(0, len(cate_words)-1):\n",
    "        if cate_words[i] not in tree_dict:\n",
    "            tree_dict[cate_words[i]] = {\"next\": set(), \"IDs\": set()}\n",
    "        tree_dict[cate_words[i]][\"next\"].add(cate_words[i+1])\n",
    "\n",
    "    if cate_words[-1] not in tree_dict:\n",
    "        tree_dict[cate_words[-1]] = {\"next\": set(), \"IDs\": set()}\n",
    "    tree_dict[cate_words[-1]][\"IDs\"].add(str(id))\n",
    "\n",
    "for id in dataset.keys():\n",
    "    if id in select_sampleID:\n",
    "        if len(dataset[id][\"category\"]) == 0 or dataset[id][\"category\"][-1] == \"</span></span></span>\":\n",
    "            continue\n",
    "        update_tree(id, dataset[id][\"category\"], ID_tree)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:52:28.634494900Z",
     "start_time": "2023-12-12T15:52:28.352483700Z"
    }
   },
   "id": "7f01d17ec39862eb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def subset_size(cate_list, tree_dict):\n",
    "    if cate_list[-1] not in tree_dict:\n",
    "        return 0\n",
    "    return len(tree_dict[cate_list[-1]][\"IDs\"])\n",
    "\n",
    "max_size = 50\n",
    "for id in dataset.keys():\n",
    "    if len(dataset[id][\"category\"]) == 0 or dataset[id][\"category\"][-1] == \"</span></span></span>\":\n",
    "        continue\n",
    "    if subset_size(dataset[id][\"category\"], ID_tree) < max_size:\n",
    "        update_tree(id, dataset[id][\"category\"], ID_tree)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:52:40.583356800Z",
     "start_time": "2023-12-12T15:52:40.552612Z"
    }
   },
   "id": "6b4fe0df8442152d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def build_prompt_stage_1(history_IDlist, ID_title_dict):\n",
    "    # STAGE 1\n",
    "    prompt = \"Previously, the user has watched movies and tv as follows:\\n\"\n",
    "    for id in history_IDlist:\n",
    "        if id in ID_title_dict:\n",
    "            prompt += ID_title_dict[id] + \"\\n\"\n",
    "    prompt += \"Summarize the interested topics, from the most important to the least important.\"\n",
    "    return prompt\n",
    "\n",
    "def get_subset_list(items_ID, ID_title_dict):\n",
    "    l = []\n",
    "    for itemid in items_ID:\n",
    "        if itemid in ID_title_dict:\n",
    "            l.append(ID_title_dict[itemid])\n",
    "\n",
    "    return l\n",
    "\n",
    "def prompt_recall_item(items_ID, ID_title_dict, recall_num, cate_name):\n",
    "    # STAGE 2\n",
    "    prompt = \"Select the top {} movies and TV shows from the following candidate set about {} \".format(recall_num, cate_name)\n",
    "    prompt += \"to recommend to the user, ranked from the most important to the least important, without offering any explanations. \"\n",
    "    prompt += \"Please do not change the format of the movie or TV show titles during the output process.\"\n",
    "    prompt += \"Here is the provided list:\\n\"\n",
    "    index = 1\n",
    "    for itemid in items_ID:\n",
    "        if itemid in ID_title_dict:\n",
    "            prompt += \"{}. {}\\n\".format(index, ID_title_dict[itemid])\n",
    "            index += 1\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def prompt_select_subcate(subcate_list, k, cate):\n",
    "    # STAGE 2\n",
    "    prompt = \"Rank the top {} subcategories about {} from provided list based on the user's interest without any explanations:\\n\".format(k, cate)\n",
    "    \n",
    "    index = 1\n",
    "    for subcate in subcate_list:\n",
    "        prompt += \"{}. {}\\n\".format(index, subcate)\n",
    "        index += 1\n",
    "    \n",
    "    prompt += \"Do not output any subcategory that do not appear in the list above.\\n\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def build_prompt_rerank(cate_title_list):\n",
    "    # STAGE 3\n",
    "    prompt_rerank = \"Rank these pre-selected movies and tv based on user interests. \"\n",
    "    prompt_rerank += \"Be aware of ranking diversity and do not change the format of the title.\\n\"\n",
    "    index = 1\n",
    "    for subcate, itemslist in cate_title_list:\n",
    "        for item in itemslist:\n",
    "          prompt_rerank += \"{}. {}\\n\".format(index, item)\n",
    "          index += 1\n",
    "    \n",
    "    return prompt_rerank"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:52:42.056630500Z",
     "start_time": "2023-12-12T15:52:42.040897400Z"
    }
   },
   "id": "c60d9e8a3835d3fb"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_answer_list(message):\n",
    "    lines = message.split('\\n')\n",
    "    cate_list = []\n",
    "    for l in lines:\n",
    "        if len(l) == 0:\n",
    "            continue\n",
    "        if l[0].isdigit():\n",
    "            cate_name = l[l.find('.')+1:].strip()\n",
    "            cate_list.append(cate_name)\n",
    "\n",
    "    return cate_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:52:57.287074Z",
     "start_time": "2023-12-12T15:52:57.256619500Z"
    }
   },
   "id": "35418aa4135329a5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.27 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from openai==0.27) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from openai==0.27) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from openai==0.27) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from requests>=2.20->openai==0.27) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from requests>=2.20->openai==0.27) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from requests>=2.20->openai==0.27) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from requests>=2.20->openai==0.27) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from aiohttp->openai==0.27) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from aiohttp->openai==0.27) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from aiohttp->openai==0.27) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from aiohttp->openai==0.27) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from aiohttp->openai==0.27) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from aiohttp->openai==0.27) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sdsc\\anaconda3\\envs\\tfgpu\\lib\\site-packages (from tqdm->openai==0.27) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "  # ChatGPT API\n",
    "\n",
    "!pip install openai==0.27\n",
    "import random\n",
    "import time\n",
    "import openai\n",
    "import os\n",
    "\n",
    "key_list = [\"API_KEYS\"]\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(self, prompt, num_of_round):\n",
    "        self.prompt = prompt\n",
    "        self.num_of_round = num_of_round\n",
    "        self.messages = []\n",
    "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
    "        self.key_index = 0\n",
    "        self.key_list = key_list\n",
    "        self.key_list_len = len(self.key_list)\n",
    "\n",
    "    def get_api_key(self):\n",
    "        api_key = self.key_list[self.key_index]\n",
    "        self.key_index += 1\n",
    "        self.key_index %= self.key_list_len\n",
    "        return api_key\n",
    "\n",
    "    def initialize_openai_client(self, api_key):\n",
    "        openai.api_key = api_key\n",
    "\n",
    "    def ask(self, question):\n",
    "        try:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": question})\n",
    "            response = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=self.messages,\n",
    "              temperature=0.5,\n",
    "              max_tokens=1024,\n",
    "              top_p=1,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return e\n",
    "\n",
    "        message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "\n",
    "        return message\n",
    "\n",
    "    def remain_fisrtKRound(self, k):\n",
    "        self.messages = self.messages[:1+2*k]\n",
    "\n",
    "    def remain_firstKReponse(self, k):\n",
    "        temp_list = []\n",
    "        for msg in self.messages:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                temp_list.append(msg)\n",
    "\n",
    "        if len(temp_list) > k:\n",
    "           temp_list = temp_list[:k]\n",
    "\n",
    "        self.messages = temp_list\n",
    "\n",
    "    def call_chatgpt(self, question, round, max_attempts=None):\n",
    "        if max_attempts == None:\n",
    "            max_attempts = self.key_list_len\n",
    "        for _ in range(max_attempts):\n",
    "            api_key = self.get_api_key()\n",
    "            self.initialize_openai_client(api_key)\n",
    "            message = None\n",
    "            try:\n",
    "                self.messages.append({\"role\": \"user\", \"content\": question})\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=self.messages,\n",
    "                    temperature=0.5,\n",
    "                    max_tokens=1024,\n",
    "                    top_p=1\n",
    "                )\n",
    "                message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "        \n",
    "                if response.choices:\n",
    "                    return message\n",
    "        \n",
    "            except (openai.error.RateLimitError, openai.error.AuthenticationError) as e:\n",
    "                # print(f\"API Error: {e}\")\n",
    "                self.remain_fisrtKRound[round-1]\n",
    "                time.sleep(20)\n",
    "                continue\n",
    "        \n",
    "            except Exception as e:\n",
    "                print(f\"Unknown Error: {e}\")\n",
    "                continue\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:53:02.249611900Z",
     "start_time": "2023-12-12T15:52:59.246580900Z"
    }
   },
   "id": "87fccb42b940abd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "chatgpt = Conversation(\"\", 30)\n",
    "recall_subset = 4\n",
    "steps = 50\n",
    "Log_file = \"AmazonLog.txt\"\n",
    "\n",
    "with open(Log_file, \"w\") as f:\n",
    "    for user_id in select_sampleID:\n",
    "        print(\"User ID:\", user_id, file = f)\n",
    "        if len(dataset[user_id][\"history\"]) == 0:\n",
    "            print(\"User history too short: \", user_id)\n",
    "            continue\n",
    "        # STAGE 1\n",
    "        prompt1 = build_prompt_stage_1(dataset[user_id][\"history\"], ID_title_dict)\n",
    "        print(\"USER:\", file = f)\n",
    "        print(prompt1, file = f)\n",
    "        message1 = chatgpt.call_chatgpt(prompt1, 1)\n",
    "        print(\"ChatGPT:\", file = f)\n",
    "        print(message1, file = f)\n",
    "    \n",
    "        # STAGE 2\n",
    "        recall_all = 20\n",
    "        stack = [\"Movies & TV\"] # Root node\n",
    "        recall_list = []\n",
    "        cate_title_list = []\n",
    "\n",
    "        leaf_i = 0\n",
    "        \n",
    "        import sys\n",
    "        cate_count = defaultdict(int)\n",
    "        while len(recall_list) < recall_all:\n",
    "            time.sleep(20)\n",
    "            if len(stack) == 0:\n",
    "                break\n",
    "            cate = stack[-1]\n",
    "            stack.pop()\n",
    "            print(cate)\n",
    "            cate_count[cate] += 1\n",
    "            if cate_count[cate] > 5:\n",
    "                sys.exit(-1)\n",
    "            if len(ID_tree[cate][\"next\"]) == 0:\n",
    "                subset_size = len(ID_tree[cate][\"IDs\"])\n",
    "                recall_num = min(subset_size, recall_subset)\n",
    "                if recall_num == 0:\n",
    "                    continue\n",
    "            \n",
    "                chatgpt.remain_fisrtKRound(1)\n",
    "                item_title_list = get_subset_list(list(ID_tree[cate][\"IDs\"]), ID_title_dict)\n",
    "                \n",
    "                prompt2 = prompt_recall_item(list(ID_tree[cate][\"IDs\"]), ID_title_dict, recall_num, cate)\n",
    "                if len(item_title_list) == 1:\n",
    "                    message2 = \"1. {}\".format(item_title_list[0])\n",
    "                else:\n",
    "                    message2 = chatgpt.call_chatgpt(prompt2, 2)\n",
    "                subset_list = get_answer_list(message2)\n",
    "                if len(subset_list) == 0 or subset_list[-1] not in item_title_list:\n",
    "                    stack.append(cate)\n",
    "                    continue\n",
    "                leaf_i += 1  \n",
    "                print(\"USER:\", file = f)\n",
    "                print(prompt2, file = f)\n",
    "                print(\"ChatGPT:\", file = f)\n",
    "                print(message2, file = f)\n",
    "                recall_list.extend(subset_list)\n",
    "                cate_title_list.append((cate, subset_list))\n",
    "            else:\n",
    "                subset_size = len(ID_tree[cate][\"next\"])\n",
    "                recall_num = min(subset_size, recall_subset)\n",
    "                if recall_num == 0:\n",
    "                    continue\n",
    "        \n",
    "                prompt2 = prompt_select_subcate(list(ID_tree[cate][\"next\"]), recall_num, cate)\n",
    "                chatgpt.remain_fisrtKRound(1)\n",
    "                message2 = chatgpt.call_chatgpt(prompt2, 2)\n",
    "                subset_list = get_answer_list(message2)\n",
    "                if len(subset_list) == 0:\n",
    "                    stack.append(cate)\n",
    "                    continue\n",
    "                replay = False\n",
    "                for subcate in subset_list:\n",
    "                    if subcate not in ID_tree.keys():\n",
    "                        replay = True\n",
    "                if replay:\n",
    "                    stack.append(cate)\n",
    "                    continue\n",
    "        \n",
    "        \n",
    "                print(\"USER:\", file = f)\n",
    "                print(prompt2, file = f)\n",
    "                print(\"ChatGPT:\", file = f)\n",
    "                print(message2, file = f)\n",
    "                \n",
    "                for subcate in subset_list[::-1]:\n",
    "                    stack.append(subcate)\n",
    "        \n",
    "        # STAGE 3\n",
    "        # Re-rank\n",
    "        prompt3 = build_prompt_rerank(cate_title_list)\n",
    "        print(\"USER:\", file = f)\n",
    "        print(prompt3, file = f)\n",
    "        chatgpt.remain_fisrtKRound(1)\n",
    "        message3 = chatgpt.call_chatgpt(prompt3, 2)\n",
    "        print(\"ChatGPT:\", file = f)\n",
    "        print(message3, file = f)\n",
    "        \n",
    "        # Evaluation\n",
    "        rerank_list = get_answer_list(message3)\n",
    "        recall_success = 0\n",
    "        for title in rerank_list:\n",
    "            if title in title_ID_dict and title_ID_dict[title] == user_id:\n",
    "                recall_success = 1\n",
    "        print(\"Recall_rate: {}\\n\".format(recall_success), file = f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d280b17d66e7da15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "562df72f5242718c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
